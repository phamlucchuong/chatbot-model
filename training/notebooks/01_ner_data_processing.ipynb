{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdba96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9043ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sentence_id  token      label\n",
      "0            1    Tôi          O\n",
      "1            1     bị          O\n",
      "2            1    đau  B-SYMPTOM\n",
      "3            1    đầu  I-SYMPTOM\n",
      "4            1     và          O\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/train_data_ner.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61997cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_spacy_format(data_string):\n",
    "    # Đọc dữ liệu từ string\n",
    "    data_io = io.StringIO(data_string)\n",
    "    df = pd.read_csv(data_io)\n",
    "    \n",
    "    # Loại bỏ khoảng trắng thừa từ tên cột\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Loại bỏ các dòng NaN (nếu có)\n",
    "    df = df.dropna(subset=['sentence_id', 'token', 'label'])\n",
    "    \n",
    "    spacy_data = []\n",
    "    \n",
    "    # Nhóm theo sentence_id\n",
    "    grouped = df.groupby('sentence_id')\n",
    "    \n",
    "    for _, group in grouped:\n",
    "        tokens = group['token'].tolist()\n",
    "        labels = group['label'].tolist()\n",
    "        \n",
    "        raw_text = \"\"\n",
    "        token_offsets = [] # Lưu (start_char, end_char) cho mỗi token\n",
    "        \n",
    "        current_char = 0\n",
    "        for token in tokens:\n",
    "            token = str(token) # Đảm bảo token là string\n",
    "            start = current_char\n",
    "            end = start + len(token)\n",
    "            token_offsets.append((start, end))\n",
    "            \n",
    "            raw_text += token + \" \"\n",
    "            current_char = end + 1 # +1 cho dấu cách\n",
    "            \n",
    "        raw_text = raw_text.strip() # Xóa dấu cách cuối cùng\n",
    "        \n",
    "        entities = []\n",
    "        \n",
    "        current_entity_label = None\n",
    "        current_entity_start_token_idx = None\n",
    "        \n",
    "        for i, label in enumerate(labels):\n",
    "            if label.startswith(\"B-\"):\n",
    "                # Nếu đang có 1 thực thể, lưu nó lại trước\n",
    "                if current_entity_label:\n",
    "                    start_char = token_offsets[current_entity_start_token_idx][0]\n",
    "                    # Vị trí kết thúc là vị trí kết thúc của token (i-1)\n",
    "                    end_char = token_offsets[i - 1][1]\n",
    "                    entities.append((start_char, end_char, current_entity_label))\n",
    "                \n",
    "                # Bắt đầu thực thể mới\n",
    "                current_entity_label = label.split(\"-\")[1]\n",
    "                current_entity_start_token_idx = i\n",
    "            \n",
    "            elif label.startswith(\"I-\"):\n",
    "                # Nếu token I- không khớp với B- (lỗi gán nhãn)\n",
    "                if not current_entity_label or label.split(\"-\")[1] != current_entity_label:\n",
    "                    # Bỏ qua token I- lỗi này và đóng thực thể cũ nếu có\n",
    "                    if current_entity_label:\n",
    "                        start_char = token_offsets[current_entity_start_token_idx][0]\n",
    "                        end_char = token_offsets[i - 1][1]\n",
    "                        entities.append((start_char, end_char, current_entity_label))\n",
    "                    current_entity_label = None\n",
    "                    current_entity_start_token_idx = None\n",
    "            \n",
    "            elif label == \"O\":\n",
    "                # Nếu gặp 'O', đóng thực thể hiện tại (nếu có)\n",
    "                if current_entity_label:\n",
    "                    start_char = token_offsets[current_entity_start_token_idx][0]\n",
    "                    end_char = token_offsets[i - 1][1]\n",
    "                    entities.append((start_char, end_char, current_entity_label))\n",
    "                current_entity_label = None\n",
    "                current_entity_start_token_idx = None\n",
    "        \n",
    "        # Xử lý thực thể cuối cùng trong câu\n",
    "        if current_entity_label:\n",
    "            start_char = token_offsets[current_entity_start_token_idx][0]\n",
    "            end_char = token_offsets[len(tokens) - 1][1] # Lấy vị trí cuối của token cuối cùng\n",
    "            entities.append((start_char, end_char, current_entity_label))\n",
    "            \n",
    "        spacy_data.append((raw_text, {\"entities\": entities}))\n",
    "        \n",
    "    return spacy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b13be49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANH SÁCH DỮ LIỆU HUẤN LUYỆN (ĐỊNH DẠNG SPACY):\n",
      "\n",
      "('Tôi bị đau đầu và sốt nhẹ', {'entities': [(7, 14, 'SYMPTOM'), (18, 25, 'SYMPTOM')]})\n",
      "('Mấy hôm nay tôi ho khan và đau họng', {'entities': [(16, 23, 'SYMPTOM'), (27, 35, 'SYMPTOM')]})\n",
      "('Tôi bị sổ mũi và nghẹt mũi mấy ngày nay', {'entities': [(7, 13, 'SYMPTOM'), (17, 26, 'SYMPTOM')]})\n",
      "('Cơ thể tôi rất mệt mỏi và uể oải', {'entities': [(15, 22, 'SYMPTOM'), (26, 32, 'SYMPTOM')]})\n",
      "('Tôi có triệu chứng ớn lạnh và đau nhức toàn thân', {'entities': [(19, 26, 'SYMPTOM'), (30, 48, 'SYMPTOM')]})\n",
      "('Sốt cao và ho có phải là triệu chứng của bệnh cảm cúm không', {'entities': [(0, 7, 'SYMPTOM'), (11, 13, 'SYMPTOM'), (46, 53, 'DISEASE')]})\n",
      "('Cháu nhà tôi bị chảy nước mũi liên tục', {'entities': [(16, 29, 'SYMPTOM')]})\n",
      "('Ngoài đau họng tôi còn bị mất vị giác', {'entities': [(6, 14, 'SYMPTOM'), (26, 37, 'SYMPTOM')]})\n",
      "('Tôi cảm thấy mệt mỏi và buồn nôn', {'entities': [(13, 20, 'SYMPTOM'), (24, 32, 'SYMPTOM')]})\n",
      "('Con tôi bị sốt cao và rét run', {'entities': [(11, 18, 'SYMPTOM'), (22, 29, 'SYMPTOM')]})\n",
      "('Triệu chứng hắt hơi và chảy nước mũi là dấu hiệu cảm lạnh đúng không', {'entities': [(12, 19, 'SYMPTOM'), (23, 36, 'SYMPTOM'), (49, 57, 'DISEASE')]})\n",
      "('Tôi bị ho có đờm đã 3 ngày', {'entities': [(7, 16, 'SYMPTOM')]})\n",
      "('Cổ họng tôi đau rát khi nuốt', {'entities': [(12, 19, 'SYMPTOM')]})\n",
      "('Sáng nay tôi thức dậy thấy đau nhức cơ bắp', {'entities': [(27, 42, 'SYMPTOM')]})\n",
      "('Tôi bị nghẹt mũi nặng và khó thở', {'entities': [(7, 16, 'SYMPTOM'), (25, 32, 'SYMPTOM')]})\n",
      "('Tôi không sốt nhưng rất mệt', {'entities': [(10, 13, 'SYMPTOM'), (24, 27, 'SYMPTOM')]})\n",
      "('Em bé bị sổ mũi và ho nhẹ', {'entities': [(9, 15, 'SYMPTOM'), (19, 25, 'SYMPTOM')]})\n",
      "('Tôi bị cảm lạnh và sốt cao', {'entities': [(7, 15, 'DISEASE'), (19, 26, 'SYMPTOM')]})\n",
      "('Đau cơ và sốt là triệu chứng của bệnh nào', {'entities': [(0, 6, 'SYMPTOM'), (10, 13, 'SYMPTOM'), (33, 41, 'DISEASE')]})\n",
      "('Tôi bị đau đầu dữ dội và buồn nôn', {'entities': [(7, 14, 'SYMPTOM'), (25, 33, 'SYMPTOM')]})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Chạy chuyển đổi\n",
    "TRAIN_DATA = convert_to_spacy_format(df.to_csv(index=False))\n",
    "\n",
    "# In kết quả\n",
    "print(\"DANH SÁCH DỮ LIỆU HUẤN LUYỆN (ĐỊNH DẠNG SPACY):\\n\")\n",
    "for item in TRAIN_DATA:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7eb0872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu thành công 20 dòng vào tệp '../data/processed/train_data.spacy.jsonl'\n"
     ]
    }
   ],
   "source": [
    "# --- PHẦN MỚI: LƯU VÀO TỆP .JSONL ---\n",
    "output_file = \"../data/processed/train_data.spacy.jsonl\"\n",
    "count = 0\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            # Tạo đối tượng JSON cho mỗi dòng\n",
    "            # Định dạng này hơi khác một chút, chỉ lưu text và các thực thể\n",
    "            # để dễ dàng đọc bằng các thư viện khác.\n",
    "            # Định dạng (text, {\"entities\": [...]}) là cho code Python, \n",
    "            # còn định dạng JSONL thường là {\"text\": ..., \"entities\": ...}\n",
    "            line_data = {\"text\": text, \"entities\": annotations['entities']}\n",
    "            \n",
    "            # Ghi dòng JSON vào tệp\n",
    "            f.write(json.dumps(line_data, ensure_ascii=False) + '\\n')\n",
    "            count += 1\n",
    "\n",
    "    print(f\"Đã lưu thành công {count} dòng vào tệp '{output_file}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi khi lưu tệp: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
